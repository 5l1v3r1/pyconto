<html>
<head> <style>  <!-- /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
{margin:0cm; margin-bottom:.0001pt; font-size:12.0pt; font-family:"Times; New Roman";}
p.MsoPlainText, li.MsoPlainText, div.MsoPlainText
{margin:0cm; margin-bottom:.0001pt; font-size:10.0pt; font-family:"Courier New";}
@page Section1  {size:595.3pt 841.9pt; margin:72.0pt 57.6pt 72.0pt 57.6pt;}
div.Section1    {page:Section1;}
-->  </style> </head>
<body lang=EN-US>  <div class=Section1>
<p class=MsoPlainText>Dynamics of noisy neural networks with complex network architecture</p>
<p class=MsoPlainText>&nbsp;</p>
<p class=MsoPlainText>ALEXANDER GOLTSEV</p>
<p class=MsoPlainText>DEPARTAMENTO DE FISICA DA UNIVERSIDADE DE AVEIRO,</p>
<p class=MsoPlainText>&nbsp;</p>

<p class=MsoPlainText>A simple model of stochastic dynamics of neural networks with complex network architecture is proposed. A neural network consists of excitatory and inhibitory neurons with type 1 and type 2 neural dynamics which fire both regular trains of spikes and random trains with the Poisson distribution. We take into account processes of spontaneous neural activity, which plays the role of noise, the activation of neurons by a stimulus or neural pacemakers, and interactions between neurons. Explicit rate equations describing the evolution of the global neuronal activity are derived. Although the model is simple, it demonstrates various patterns of self-organization of neural networks, hybrid phase transitions, hysteresis phenomena, neural avalanches and a rich set of dynamical phenomena driven by noise: decaying and stable oscillations, and stochastic resonance. We show that at a critical level of noise a neural network undergoes a dynamical phase transition from a state with incoherent neurons to a state with synchronized neurons and global oscillations. Stochastic resonance is a precursor of global oscillations. We compare our results with experimental data in real neural networks (living neural networks, the mammalian brain). Comprehensive simulations support the obtained analytical results. Our simulations reveal that even small groups of 50-1000 neurons display oscillations similar to large networks. We study the role of the network structure, and compare dynamics of neural networks on classical random graphs and scale-free networks. We demonstrate that dynamics of neural networks with fat-tailed degree distributions are robust against random damage. Moreover, in these networks a weak spontaneous neural activity or a small concentration of neural pacemakers is enough to activate a finite fraction of the neural networks. This is so called background spontaneous activity of neural networks.</p>
</div>
</body>
</html>
