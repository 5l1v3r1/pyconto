<html>
<head> <style>  <!-- /* Style Definitions */
p.MsoNormal, li.MsoNormal, div.MsoNormal
{margin:0cm; margin-bottom:.0001pt; font-size:12.0pt; font-family:"Times; New Roman";}
p.MsoPlainText, li.MsoPlainText, div.MsoPlainText
{margin:0cm; margin-bottom:.0001pt; font-size:10.0pt; font-family:"Courier New";}
@page Section1  {size:595.3pt 841.9pt; margin:72.0pt 57.6pt 72.0pt 57.6pt;}
div.Section1    {page:Section1;}
-->  </style> </head>
<body lang=EN-US>  <div class=Section1>
<p class=MsoPlainText>Benchmark graphs and evaluation of community detection algorithms</p>
<p class=MsoPlainText>&nbsp;</p>
<p class=MsoPlainText>SUNE LEHMANN</p>
<p class=MsoPlainText>INSTITUTE FOR QUANTITATIVE SOCIAL SCIENCE, HARVARD</p>
<p class=MsoPlainText>&nbsp;</p>

<p class=MsoPlainText>In recent years, a proliferation of community detection algorithms has occurred, and so it has become important to develop testing procedures to evaluate performance and accuracy in a fair and unbiased manner. Many current tests consist of benchmarks graphs with artificially enforced community structure, coupled with performance measures such as mutual information between designed and detected structure. We show that this general approach can be problematic, in particular with respect to testing disparate community methods. Further, benchmark tests often fail to reproduce features present in real networks (for example clustering), which may cause performance estimated on benchmark graphs to correlate poorly with real-world performance. We propose an alternative testing method based on real world meta-data.</p>
</div>
</body>
</html>
